{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from src.data_models.camels_ch import CamelsCH, CamelsCHConfig, get_all_gauge_ids\n",
    "from src.data_models.dataset import HydroDataset\n",
    "from src.data_models.preprocessing import (\n",
    "    scale_time_series,\n",
    "    scale_static_attributes,\n",
    "    inverse_scale_static_attributes,\n",
    "    inverse_scale_time_series,\n",
    ")\n",
    "\n",
    "from utils.metrics import nash_sutcliffe_efficiency\n",
    "from src.data_models.datamodule import HydroDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and prepare CAMELS-CH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "camels_config = CamelsCHConfig(\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/timeseries/observation_based/\",\n",
    "    timeseries_pattern=\"CAMELS_CH_obs_based_*.csv\",\n",
    "    static_attributes_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/static_attributes\",\n",
    "    use_climate=True,\n",
    "    use_geology=True,\n",
    "    use_glacier=False,\n",
    "    use_human_influence=False,\n",
    "    use_hydrogeology=False,\n",
    "    use_hydrology=False,\n",
    "    use_landcover=True,\n",
    "    use_soil=True,\n",
    "    use_topographic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded time series data for 331 stations\n",
      "Loading climate attributes\n",
      "Loading geology attributes\n",
      "Loading landcover attributes\n",
      "Loading soil attributes\n",
      "Loading topographic attributes\n",
      "Loaded static attributes for 331 stations\n"
     ]
    }
   ],
   "source": [
    "all_gauge_ids = get_all_gauge_ids(camels_config)\n",
    "ids_for_training = all_gauge_ids\n",
    "\n",
    "\n",
    "camels = CamelsCH(camels_config)\n",
    "camels.load_stations(ids_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_id</th>\n",
       "      <th>area</th>\n",
       "      <th>elev_mean</th>\n",
       "      <th>slope_mean</th>\n",
       "      <th>aridity</th>\n",
       "      <th>p_seasonality</th>\n",
       "      <th>frac_snow</th>\n",
       "      <th>porosity</th>\n",
       "      <th>conductivity</th>\n",
       "      <th>p_mean</th>\n",
       "      <th>geo_porosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>712.7</td>\n",
       "      <td>644.60</td>\n",
       "      <td>5.53</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.039</td>\n",
       "      <td>44.855</td>\n",
       "      <td>81.482</td>\n",
       "      <td>3.059</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>209.3</td>\n",
       "      <td>1228.27</td>\n",
       "      <td>8.13</td>\n",
       "      <td>0.369</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.170</td>\n",
       "      <td>49.508</td>\n",
       "      <td>32.419</td>\n",
       "      <td>4.983</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>5239.4</td>\n",
       "      <td>2124.19</td>\n",
       "      <td>25.72</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.436</td>\n",
       "      <td>45.708</td>\n",
       "      <td>36.593</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>3372.4</td>\n",
       "      <td>2286.71</td>\n",
       "      <td>25.82</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.474</td>\n",
       "      <td>45.247</td>\n",
       "      <td>34.908</td>\n",
       "      <td>3.401</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>1583.5</td>\n",
       "      <td>1331.63</td>\n",
       "      <td>22.10</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.223</td>\n",
       "      <td>48.837</td>\n",
       "      <td>25.776</td>\n",
       "      <td>4.869</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>6007</td>\n",
       "      <td>1531.4</td>\n",
       "      <td>1672.11</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.379</td>\n",
       "      <td>47.955</td>\n",
       "      <td>31.384</td>\n",
       "      <td>4.058</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>6008</td>\n",
       "      <td>229.7</td>\n",
       "      <td>878.60</td>\n",
       "      <td>21.26</td>\n",
       "      <td>0.536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.943</td>\n",
       "      <td>58.987</td>\n",
       "      <td>4.742</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>6009</td>\n",
       "      <td>121.6</td>\n",
       "      <td>1248.36</td>\n",
       "      <td>31.66</td>\n",
       "      <td>0.427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.761</td>\n",
       "      <td>31.715</td>\n",
       "      <td>5.446</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>6010</td>\n",
       "      <td>60.2</td>\n",
       "      <td>912.20</td>\n",
       "      <td>24.84</td>\n",
       "      <td>0.434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.189</td>\n",
       "      <td>38.748</td>\n",
       "      <td>5.953</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>6011</td>\n",
       "      <td>6617.3</td>\n",
       "      <td>1292.72</td>\n",
       "      <td>24.96</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.110</td>\n",
       "      <td>48.325</td>\n",
       "      <td>37.094</td>\n",
       "      <td>4.797</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gauge_id    area  elev_mean  slope_mean  aridity  p_seasonality  \\\n",
       "0       2004   712.7     644.60        5.53    0.597          0.159   \n",
       "1       2007   209.3    1228.27        8.13    0.369         -0.118   \n",
       "2       2009  5239.4    2124.19       25.72    0.440          0.078   \n",
       "3       2011  3372.4    2286.71       25.82    0.442          0.106   \n",
       "4       2014  1583.5    1331.63       22.10    0.316          0.279   \n",
       "..       ...     ...        ...         ...      ...            ...   \n",
       "326     6007  1531.4    1672.11       28.61    0.451          0.228   \n",
       "327     6008   229.7     878.60       21.26    0.536            NaN   \n",
       "328     6009   121.6    1248.36       31.66    0.427            NaN   \n",
       "329     6010    60.2     912.20       24.84    0.434            NaN   \n",
       "330     6011  6617.3    1292.72       24.96    0.500          0.272   \n",
       "\n",
       "     frac_snow  porosity  conductivity  p_mean  geo_porosity  \n",
       "0        0.039    44.855        81.482   3.059         0.101  \n",
       "1        0.170    49.508        32.419   4.983         0.070  \n",
       "2        0.436    45.708        36.593   3.558         0.045  \n",
       "3        0.474    45.247        34.908   3.401         0.038  \n",
       "4        0.223    48.837        25.776   4.869         0.091  \n",
       "..         ...       ...           ...     ...           ...  \n",
       "326      0.379    47.955        31.384   4.058         0.012  \n",
       "327        NaN    46.943        58.987   4.742         0.025  \n",
       "328        NaN    48.761        31.715   5.446         0.010  \n",
       "329        NaN    47.189        38.748   5.953         0.009  \n",
       "330      0.110    48.325        37.094   4.797         0.026  \n",
       "\n",
       "[331 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static = camels.get_static_attributes()\n",
    "sc = static.columns\n",
    "\n",
    "# for i in range(len(sc)):\n",
    "#     print(f\"{i}: {sc[i]}\")\n",
    "static_attributes = [\n",
    "    \"gauge_id\",\n",
    "    \"area\", \n",
    "    \"elev_mean\",  \n",
    "    \"slope_mean\",  \n",
    "    \"aridity\",  \n",
    "    \"p_seasonality\",  \n",
    "    \"frac_snow\",  \n",
    "    \"porosity\",  \n",
    "    \"conductivity\",  \n",
    "    \"p_mean\",  \n",
    "    \"geo_porosity\",  \n",
    "]\n",
    "static = static[static_attributes]\n",
    "static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = camels.get_time_series()\n",
    "data = data[\n",
    "    [\n",
    "        \"gauge_id\",\n",
    "        \"date\",\n",
    "        \"swe(mm)\",\n",
    "    ]\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configure preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_config = {\n",
    "    \"features\": {\n",
    "        \"scale_method\": \"per_basin\",\n",
    "        \"log_transform\": []\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"scale_method\": \"per_basin\",\n",
    "        \"log_transform\": False\n",
    "    },\n",
    "    \"static_features\": {\n",
    "        \"scale_method\": \"global\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = HydroDataModule(\n",
    "    time_series_df=data,\n",
    "    static_df=None,\n",
    "    group_identifier=\"gauge_id\",\n",
    "    preprocessing_config=preprocessing_config,\n",
    "    batch_size=32,\n",
    "    input_length=30,\n",
    "    output_length=5,\n",
    "    num_workers=4,\n",
    "    features=[\"swe(mm)\"],\n",
    "    # static_features=static_attributes[1:],\n",
    "    target=\"swe(mm)\",\n",
    "    train_years=10,\n",
    "    val_years=1,\n",
    "    min_test_years=1,\n",
    ")\n",
    "\n",
    "# data_module.static_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.lstm import LitLSTM\n",
    "from src.models.ealstm import LitEALSTM\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evalue and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quality Check Summary:\n",
      "Original basins: 331\n",
      "Retained basins: 297\n",
      "Excluded basins: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    571\u001b[0m     ckpt_path,\n\u001b[1;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:942\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    941\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: preparing data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 942\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_setup_hook(\u001b[38;5;28mself\u001b[39m)  \u001b[38;5;66;03m# allow user to set up LightningModule in accelerator environment\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:94\u001b[0m, in \u001b[0;36m_DataConnector.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (prepare_data_per_node \u001b[38;5;129;01mand\u001b[39;00m local_rank_zero) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m prepare_data_per_node \u001b[38;5;129;01mand\u001b[39;00m global_rank_zero):\n\u001b[0;32m---> 94\u001b[0m             \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_datamodule_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprepare_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# handle lightning module prepare data:\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:193\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningDataModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/src/data_models/datamodule.py:204\u001b[0m, in \u001b[0;36mHydroDataModule.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_time_series, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mscale_time_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf_full\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_time_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_time_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Will be filtered in setup\u001b[39;49;00m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_basin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscale_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mper_basin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Scale static features if any\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/src/data_models/preprocessing.py:101\u001b[0m, in \u001b[0;36mscale_time_series\u001b[0;34m(df_full, df_train, features, by_basin)\u001b[0m\n\u001b[1;32m    100\u001b[0m mask \u001b[38;5;241m=\u001b[39m df_full[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgauge_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m gauge_id\n\u001b[0;32m--> 101\u001b[0m train_mask \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgauge_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgauge_id\u001b[49m\n\u001b[1;32m    103\u001b[0m sc \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 35\u001b[0m\n\u001b[1;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     19\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     20\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     ],\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# model = LitLSTM(\n",
    "#     input_size=3,\n",
    "#     hidden_size=64,\n",
    "#     num_layers=1,\n",
    "#     output_size=5,\n",
    "#     target=\"discharge_spec(mm/d)\",\n",
    "# )\n",
    "\n",
    "model = LitEALSTM(\n",
    "    input_size_dyn=3,\n",
    "    input_size_stat=len(static_attributes) - 1,\n",
    "    hidden_size=64,\n",
    "    output_size=5,\n",
    "    target=\"discharge_spec(mm/d)\",\n",
    ")\n",
    "\n",
    "# Configure trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            monitor=\"val_loss\",\n",
    "            dirpath=\"checkpoints\",\n",
    "            filename=\"best-checkpoint\",\n",
    "            save_top_k=1,\n",
    "            mode=\"min\",\n",
    "        ),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_report = data_module.quality_report\n",
    "\n",
    "excluded_basins = list(quality_report[\"excluded_basins\"].keys())\n",
    "excluded_basins\n",
    "\n",
    "ids_for_training = [id for id in ids_for_training if id not in excluded_basins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, data_module)\n",
    "test_results = model.test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results\n",
    "results_df = model.test_results[\"forecast_df\"]\n",
    "horizon_metrics = model.test_results[\"horizon_metrics\"]\n",
    "\n",
    "horizons = []\n",
    "nse_values = []\n",
    "for horizon, metrics in horizon_metrics.items():\n",
    "    horizons.append(horizon)\n",
    "    nse_values.append(metrics[\"NSE\"])\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = sns.color_palette(\"Blues\", 1)\n",
    "plt.bar(horizons, nse_values, color=colors)\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel(\"Forecast Horizon (Days)\")\n",
    "plt.ylabel(\"Nash-Sutcliffe Efficiency\")\n",
    "plt.title(\"Forecast Skill by Prediction Horizon\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "sns.despine()\n",
    "\n",
    "# Set x-axis ticks to show all horizons\n",
    "plt.xticks(horizons)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(nse_values):\n",
    "    plt.text(i + 1, v, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results_df to get NSE by basin and horizon\n",
    "basin_metrics = {}\n",
    "for basin in results_df[\"basin_id\"].unique():\n",
    "    basin_data = results_df[results_df[\"basin_id\"] == basin]\n",
    "    nse_values = []\n",
    "    for horizon in range(1, max(basin_data[\"horizon\"]) + 1):\n",
    "        horizon_data = basin_data[basin_data[\"horizon\"] == horizon]\n",
    "        nse = nash_sutcliffe_efficiency(\n",
    "            horizon_data[\"observed\"].values, horizon_data[\"prediction\"].values\n",
    "        )\n",
    "        nse_values.append(nse)\n",
    "    basin_metrics[basin] = nse_values\n",
    "\n",
    "# Sort basins by NSE at horizon 1\n",
    "sorted_basins = sorted(\n",
    "    basin_metrics.keys(), key=lambda x: basin_metrics[x][0], reverse=True\n",
    ")\n",
    "basin_metrics = {basin: basin_metrics[basin] for basin in sorted_basins}\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.8 / len(basin_metrics)\n",
    "\n",
    "# Create color palette of blue shades\n",
    "colors = sns.color_palette(\"Blues\", len(basin_metrics) + 2)[2:]\n",
    "\n",
    "# Create bars for each basin\n",
    "for i, (basin, nse_values) in enumerate(basin_metrics.items()):\n",
    "    x = np.arange(len(nse_values)) + i * bar_width\n",
    "    plt.bar(x, nse_values, bar_width, label=f\"Basin {basin}\", color=colors[i])\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel(\"Forecast Horizon (Days)\", fontsize=12)\n",
    "plt.ylabel(\"Nash-Sutcliffe Efficiency\", fontsize=12)\n",
    "plt.title(\"Forecast Skill by Basin and Horizon\", fontsize=14, pad=20)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.legend(title=\"Basin ID\", title_fontsize=10, fontsize=10)\n",
    "sns.despine()\n",
    "\n",
    "# Set x-axis ticks in middle of grouped bars\n",
    "plt.xticks(\n",
    "    np.arange(len(next(iter(basin_metrics.values()))))\n",
    "    + bar_width * (len(basin_metrics) - 1) / 2,\n",
    "    np.arange(1, len(next(iter(basin_metrics.values()))) + 1),\n",
    ")\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_predictions(results_df, n_timesteps=None):\n",
    "    # Filter for horizon 1\n",
    "    horizon_1_data = results_df[results_df[\"horizon\"] == 1]\n",
    "\n",
    "    if n_timesteps:\n",
    "        # Get last n_timesteps for each basin\n",
    "        horizon_1_data = (\n",
    "            horizon_1_data.groupby(\"basin_id\").tail(n_timesteps).reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "    n_basins = len(horizon_1_data[\"basin_id\"].unique())\n",
    "    n_cols = 2\n",
    "    n_rows = (n_basins + 1) // 2\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, basin in enumerate(horizon_1_data[\"basin_id\"].unique()):\n",
    "        basin_data = horizon_1_data[horizon_1_data[\"basin_id\"] == basin]\n",
    "        ax = axes[idx]\n",
    "\n",
    "        nse = nash_sutcliffe_efficiency(\n",
    "            basin_data[\"observed\"].values, basin_data[\"prediction\"].values\n",
    "        )\n",
    "\n",
    "        x = np.arange(len(basin_data))\n",
    "        ax.plot(x, basin_data[\"observed\"], label=\"Observed\", color=\"#1d4ed8\")\n",
    "        ax.plot(\n",
    "            x,\n",
    "            basin_data[\"prediction\"],\n",
    "            label=\"Predicted\",\n",
    "            color=\"#dc2626\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"Basin {basin} (NSE: {nse:.3f})\", fontsize=12)\n",
    "        ax.set_xlabel(\"Time Step\", fontsize=10)\n",
    "        ax.set_ylabel(\"Discharge\", fontsize=10)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "        ax.legend(fontsize=9)\n",
    "        sns.despine(ax=ax)\n",
    "\n",
    "    for idx in range(n_basins, len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "plot_predictions(results_df, n_timesteps=365) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
