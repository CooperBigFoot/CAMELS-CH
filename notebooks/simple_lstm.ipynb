{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from src.data_models.camels_ch import CamelsCH, CamelsCHConfig, get_all_gauge_ids\n",
    "from src.data_models.dataset import HydroDataset\n",
    "from src.data_models.preprocessing import (\n",
    "    scale_time_series,\n",
    "    scale_static_attributes,\n",
    "    inverse_scale_static_attributes,\n",
    "    inverse_scale_time_series,\n",
    ")\n",
    "from src.data_models.caravanify import Caravanify, CaravanifyConfig \n",
    "\n",
    "from utils.metrics import nash_sutcliffe_efficiency\n",
    "from src.data_models.datamodule import HydroDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Caravanify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stations: 135\n"
     ]
    }
   ],
   "source": [
    "config = CaravanifyConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CH/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CH/post_processed/timeseries/csv\",\n",
    "    gauge_id_prefix=\"CH\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "caravan = Caravanify(config)\n",
    "ids_for_training = caravan.get_all_gauge_ids()\n",
    "\n",
    "print(f\"Total number of stations: {len(ids_for_training)}\")\n",
    "\n",
    "caravan.load_stations(ids_for_training)\n",
    "\n",
    "\n",
    "# Get data\n",
    "ts_data = caravan.get_time_series()  # MultiIndex: (gauge_id, date)\n",
    "static_data = caravan.get_static_attributes()  # Columns merged from enabled attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_columns = ts_data.columns\n",
    "ts_columns = [col for col in list(ts_columns) if col not in [\"gauge_id\", \"date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statics_to_keep = [\n",
    "    \"gauge_id\",\n",
    "    \"p_mean\",\n",
    "    \"area\",\n",
    "    \"ele_mt_sav\",\n",
    "    \"high_prec_dur\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"slp_dg_sav\",\n",
    "    \"cly_pc_sav\",\n",
    "    \"aridity_ERA5_LAND\",\n",
    "    \"aridity_FAO_PM\",\n",
    "]\n",
    "\n",
    "static_columns = static_data.columns\n",
    "static_columns = [col for col in list(static_columns) if col in statics_to_keep]\n",
    "\n",
    "static_data = static_data[static_columns]\n",
    "static_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and prepare CAMELS-CH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camels_config = CamelsCHConfig(\n",
    "#     timeseries_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/timeseries/observation_based/\",\n",
    "#     timeseries_pattern=\"CAMELS_CH_obs_based_*.csv\",\n",
    "#     static_attributes_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/static_attributes\",\n",
    "#     use_climate=False,\n",
    "#     use_geology=False,\n",
    "#     use_glacier=False,\n",
    "#     use_human_influence=False,\n",
    "#     use_hydrogeology=False,\n",
    "#     use_hydrology=False,\n",
    "#     use_landcover=False,\n",
    "#     use_soil=False,\n",
    "#     use_topographic=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_gauge_ids = get_all_gauge_ids(camels_config)\n",
    "\n",
    "# ids_for_training = all_gauge_ids[:5]\n",
    "\n",
    "# camels = CamelsCH(camels_config)\n",
    "# camels.load_stations(ids_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = camels.get_time_series()\n",
    "# data = data[\n",
    "#     [\n",
    "#         \"gauge_id\",\n",
    "#         \"date\",\n",
    "#         \"discharge_spec(mm/d)\",\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static = camels.get_static_attributes()\n",
    "# sc = static.columns\n",
    "\n",
    "# # for i in range(len(sc)):\n",
    "# #     print(f\"{i}: {sc[i]}\")\n",
    "# static_attributes = [\n",
    "#     \"gauge_id\",\n",
    "#     \"area\", \n",
    "#     \"elev_mean\",  \n",
    "#     \"slope_mean\",  \n",
    "#     \"aridity\",  \n",
    "#     \"p_seasonality\",  \n",
    "#     \"frac_snow\",  \n",
    "#     \"porosity\",  \n",
    "#     \"conductivity\",  \n",
    "#     \"p_mean\",  \n",
    "#     \"geo_porosity\",  \n",
    "# ]\n",
    "# static = static[static_attributes]\n",
    "# static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configure preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_config = {\n",
    "    \"features\": {\n",
    "        \"scale_method\": \"per_basin\",\n",
    "        \"log_transform\": []\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"scale_method\": \"per_basin\",\n",
    "        \"log_transform\": False\n",
    "    },\n",
    "    \"static_features\": {\n",
    "        \"scale_method\": \"global\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_length = 10\n",
    "\n",
    "\n",
    "data_module = HydroDataModule(\n",
    "    time_series_df=ts_data,\n",
    "    static_df=static_data,\n",
    "    group_identifier=\"gauge_id\",\n",
    "    preprocessing_config=preprocessing_config,\n",
    "    batch_size=32,\n",
    "    input_length=30,\n",
    "    output_length=output_length,\n",
    "    num_workers=4,\n",
    "    features=ts_columns,\n",
    "    static_features=static_columns,\n",
    "    target=\"streamflow\",\n",
    "    train_years=15,\n",
    "    val_years=3,\n",
    "    min_test_years=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.lstm import LitLSTM\n",
    "from src.models.ealstm import LitEALSTM\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evalue and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LitLSTM(\n",
    "#     input_size=len(ts_columns),\n",
    "#     hidden_size=16,\n",
    "#     num_layers=1,\n",
    "#     output_size=output_length,\n",
    "#     target=data_module.target,\n",
    "# )\n",
    "\n",
    "model = LitEALSTM(\n",
    "    input_size_dyn=len(ts_columns),\n",
    "    input_size_stat=len(static_columns) - 1,\n",
    "    hidden_size=64,\n",
    "    output_size=output_length,\n",
    "    target=data_module.target,\n",
    ")\n",
    "\n",
    "# Configure trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            monitor=\"val_loss\",\n",
    "            dirpath=\"checkpoints\",\n",
    "            filename=\"best-checkpoint\",\n",
    "            save_top_k=1,\n",
    "            mode=\"min\",\n",
    "        ),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_report = data_module.quality_report\n",
    "\n",
    "excluded_basins = list(quality_report[\"excluded_basins\"].keys())\n",
    "excluded_basins\n",
    "\n",
    "ids_for_training = [id for id in ids_for_training if id not in excluded_basins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, data_module)\n",
    "test_results = model.test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results\n",
    "results_df = model.test_results[\"forecast_df\"]\n",
    "horizon_metrics = model.test_results[\"horizon_metrics\"]\n",
    "\n",
    "horizons = []\n",
    "nse_values = []\n",
    "for horizon, metrics in horizon_metrics.items():\n",
    "    horizons.append(horizon)\n",
    "    nse_values.append(metrics[\"NSE\"])\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = sns.color_palette(\"Blues\", 1)\n",
    "plt.bar(horizons, nse_values, color=colors)\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel(\"Forecast Horizon (Days)\")\n",
    "plt.ylabel(\"Nash-Sutcliffe Efficiency\")\n",
    "plt.title(\"Forecast Skill by Prediction Horizon\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "sns.despine()\n",
    "\n",
    "# Set x-axis ticks to show all horizons\n",
    "plt.xticks(horizons)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(nse_values):\n",
    "    plt.text(i + 1, v, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results_df to get NSE by basin and horizon\n",
    "basin_metrics = {}\n",
    "for basin in results_df[\"basin_id\"].unique():\n",
    "    basin_data = results_df[results_df[\"basin_id\"] == basin]\n",
    "    nse_values = []\n",
    "    for horizon in range(1, max(basin_data[\"horizon\"]) + 1):\n",
    "        horizon_data = basin_data[basin_data[\"horizon\"] == horizon]\n",
    "        nse = nash_sutcliffe_efficiency(\n",
    "            horizon_data[\"observed\"].values, horizon_data[\"prediction\"].values\n",
    "        )\n",
    "        nse_values.append(nse)\n",
    "    basin_metrics[basin] = nse_values\n",
    "\n",
    "# Sort basins by NSE at horizon 1\n",
    "sorted_basins = sorted(\n",
    "    basin_metrics.keys(), key=lambda x: basin_metrics[x][0], reverse=True\n",
    ")\n",
    "basin_metrics = {basin: basin_metrics[basin] for basin in sorted_basins}\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.8 / len(basin_metrics)\n",
    "\n",
    "# Create color palette of blue shades\n",
    "colors = sns.color_palette(\"Blues\", len(basin_metrics) + 2)[2:]\n",
    "\n",
    "# Create bars for each basin\n",
    "for i, (basin, nse_values) in enumerate(basin_metrics.items()):\n",
    "    x = np.arange(len(nse_values)) + i * bar_width\n",
    "    plt.bar(x, nse_values, bar_width, label=f\"Basin {basin}\", color=colors[i])\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel(\"Forecast Horizon (Days)\", fontsize=12)\n",
    "plt.ylabel(\"Nash-Sutcliffe Efficiency\", fontsize=12)\n",
    "plt.title(\"Forecast Skill by Basin and Horizon\", fontsize=14, pad=20)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.legend(title=\"Basin ID\", title_fontsize=10, fontsize=10)\n",
    "sns.despine()\n",
    "\n",
    "# Set x-axis ticks in middle of grouped bars\n",
    "plt.xticks(\n",
    "    np.arange(len(next(iter(basin_metrics.values()))))\n",
    "    + bar_width * (len(basin_metrics) - 1) / 2,\n",
    "    np.arange(1, len(next(iter(basin_metrics.values()))) + 1),\n",
    ")\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_predictions(results_df, n_timesteps=None):\n",
    "    # Filter for horizon 1\n",
    "    horizon_1_data = results_df[results_df[\"horizon\"] == 1]\n",
    "\n",
    "    if n_timesteps:\n",
    "        # Get last n_timesteps for each basin\n",
    "        horizon_1_data = (\n",
    "            horizon_1_data.groupby(\"basin_id\").tail(n_timesteps).reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "    n_basins = len(horizon_1_data[\"basin_id\"].unique())\n",
    "    n_cols = 2\n",
    "    n_rows = (n_basins + 1) // 2\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, basin in enumerate(horizon_1_data[\"basin_id\"].unique()):\n",
    "        basin_data = horizon_1_data[horizon_1_data[\"basin_id\"] == basin]\n",
    "        ax = axes[idx]\n",
    "\n",
    "        nse = nash_sutcliffe_efficiency(\n",
    "            basin_data[\"observed\"].values, basin_data[\"prediction\"].values\n",
    "        )\n",
    "\n",
    "        x = np.arange(len(basin_data))\n",
    "        ax.plot(x, basin_data[\"observed\"], label=\"Observed\", color=\"#1d4ed8\")\n",
    "        ax.plot(\n",
    "            x,\n",
    "            basin_data[\"prediction\"],\n",
    "            label=\"Predicted\",\n",
    "            color=\"#dc2626\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"Basin {basin} (NSE: {nse:.3f})\", fontsize=12)\n",
    "        ax.set_xlabel(\"Time Step\", fontsize=10)\n",
    "        ax.set_ylabel(\"Discharge\", fontsize=10)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "        ax.legend(fontsize=9)\n",
    "        sns.despine(ax=ax)\n",
    "\n",
    "    for idx in range(n_basins, len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "plot_predictions(results_df, n_timesteps=365) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
