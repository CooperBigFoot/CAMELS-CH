{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the CSV files\n",
    "directory = \"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CL/post_processed/attributes/CL\"\n",
    "\n",
    "\n",
    "# Function to transform gauge_id\n",
    "def transform_gauge_id(gauge_id):\n",
    "    if gauge_id.startswith(\"camelscl_\"):\n",
    "        return f\"CL_{gauge_id[9:]}\"  # Remove 'camelscl_' and add 'CL_'\n",
    "    return gauge_id\n",
    "\n",
    "\n",
    "# Iterate through all CSV files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Read the CSV file\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Check if the file has a gauge_id column\n",
    "            if \"gauge_id\" in df.columns:\n",
    "                # Apply the transformation to the gauge_id column\n",
    "                df[\"gauge_id\"] = df[\"gauge_id\"].apply(transform_gauge_id)\n",
    "\n",
    "                # Save the modified file back to the same location\n",
    "                df.to_csv(file_path, index=False)\n",
    "                print(f\"Processed: {filename}\")\n",
    "            else:\n",
    "                print(f\"Warning: {filename} does not have a gauge_id column\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "print(\"All files processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the shapefile\n",
    "path_to_shapefile = \"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/USA/post_processed/shapefiles/USA/USA_basin_shapes.shp\"\n",
    "\n",
    "# Read the shapefile\n",
    "gdf = gpd.read_file(path_to_shapefile)\n",
    "\n",
    "# Print the original first few rows\n",
    "print(\"Original data:\")\n",
    "print(gdf.head())\n",
    "\n",
    "# Update the gauge_id field to replace \"camels_\" with \"USA_\"\n",
    "gdf['gauge_id'] = gdf['gauge_id'].str.replace('camels_', 'USA_')\n",
    "\n",
    "# Print the updated first few rows\n",
    "print(\"\\nUpdated data:\")\n",
    "print(gdf.head())\n",
    "\n",
    "# Save the updated shapefile\n",
    "gdf.to_file(path_to_shapefile)\n",
    "\n",
    "print(f\"\\nShapefile updated and saved to {path_to_shapefile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from src.data_models.caravanify import Caravanify, CaravanifyConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CaravanifyConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CL/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CL/post_processed/timeseries/csv\",\n",
    "    gauge_id_prefix=\"CL\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "\n",
    "caravan = Caravanify(config)\n",
    "ids_for_training = caravan.get_all_gauge_ids()\n",
    "\n",
    "print(f\"Total number of stations: {len(ids_for_training)}\")\n",
    "\n",
    "caravan.load_stations(ids_for_training)\n",
    "\n",
    "\n",
    "# Get data\n",
    "ts_data = caravan.get_time_series()\n",
    "static_data = caravan.get_static_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate gauge IDs\n",
    "unique_ids = ts_data[\"gauge_id\"].unique()\n",
    "print(f\"Unique gauge IDs: {len(unique_ids)}\")\n",
    "\n",
    "# Check if we have both camelscl_ and CL_ prefixes\n",
    "prefixes = set([id_[:3] if id_.startswith(\"CL_\") else id_[:9] for id_ in unique_ids])\n",
    "print(f\"Different prefixes found: {prefixes}\")\n",
    "\n",
    "# Count occurrences of each ID\n",
    "id_counts = ts_data[\"gauge_id\"].value_counts().reset_index()\n",
    "id_counts.columns = [\"gauge_id\", \"count\"]\n",
    "\n",
    "# Check if same ID appears with different prefixes\n",
    "id_without_prefix = []\n",
    "for id_ in unique_ids:\n",
    "    if id_.startswith(\"CL_\"):\n",
    "        id_without_prefix.append(id_[3:])\n",
    "    elif id_.startswith(\"camelscl_\"):\n",
    "        id_without_prefix.append(id_[9:])\n",
    "    else:\n",
    "        id_without_prefix.append(id_)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "duplicate_base_ids = [\n",
    "    item for item, count in Counter(id_without_prefix).items() if count > 1\n",
    "]\n",
    "print(f\"Number of IDs that appear with multiple prefixes: {len(duplicate_base_ids)}\")\n",
    "\n",
    "if duplicate_base_ids:\n",
    "    print(\"Examples of duplicate IDs:\")\n",
    "    for base_id in duplicate_base_ids[:5]:  # Show first 5 examples\n",
    "        matching_ids = [id_ for id_ in unique_ids if id_.endswith(base_id)]\n",
    "        print(f\"Base ID {base_id}: {matching_ids}\")\n",
    "\n",
    "# Check for duplicate dates for the same gauge_id\n",
    "duplicate_dates = ts_data.duplicated(subset=[\"gauge_id\", \"date\"], keep=False)\n",
    "if duplicate_dates.any():\n",
    "    print(f\"\\nFound {duplicate_dates.sum()} duplicate (gauge_id, date) combinations\")\n",
    "    print(\"Sample of duplicates:\")\n",
    "    print(ts_data[duplicate_dates].head(10)[[\"gauge_id\", \"date\"]])\n",
    "\n",
    "# Check file count in the directory\n",
    "import os\n",
    "\n",
    "timeseries_dir = \"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CL/post_processed/timeseries/csv/CL\"\n",
    "csv_files = [f for f in os.listdir(timeseries_dir) if f.endswith(\".csv\")]\n",
    "print(f\"\\nCSV files in directory: {len(csv_files)}\")\n",
    "\n",
    "# Check if both naming patterns exist in the directory\n",
    "camelscl_files = [f for f in csv_files if f.startswith(\"camelscl_\")]\n",
    "cl_files = [f for f in csv_files if f.startswith(\"CL_\")]\n",
    "print(f\"Files with 'camelscl_' prefix: {len(camelscl_files)}\")\n",
    "print(f\"Files with 'CL_' prefix: {len(cl_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the gauge_id numbers themselves are unique\n",
    "base_ids = [id_[3:] for id_ in ts_data['gauge_id'].unique()]\n",
    "len(base_ids) == len(set(base_ids))  # Should return True if all are unique\n",
    "\n",
    "# Analyze the distribution of IDs\n",
    "import re\n",
    "id_patterns = {}\n",
    "for id_ in ts_data['gauge_id'].unique():\n",
    "    # Extract the numeric pattern\n",
    "    match = re.match(r'CL_(\\d+)', id_)\n",
    "    if match:\n",
    "        pattern = match.group(1)[:4]  # First 4 digits\n",
    "        if pattern in id_patterns:\n",
    "            id_patterns[pattern] += 1\n",
    "        else:\n",
    "            id_patterns[pattern] = 1\n",
    "\n",
    "# Show patterns with most occurrences\n",
    "import pandas as pd\n",
    "patterns_df = pd.DataFrame(list(id_patterns.items()), columns=['Pattern', 'Count'])\n",
    "patterns_df = patterns_df.sort_values('Count', ascending=False)\n",
    "print(patterns_df.head(10))\n",
    "\n",
    "# You could also check the attributes file to see if it has the expected number of basins\n",
    "attributes_path = \"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CL/post_processed/attributes\"\n",
    "import os\n",
    "attribute_files = os.listdir(attributes_path)\n",
    "print(f\"Attribute files: {attribute_files}\")\n",
    "\n",
    "# If you have access to an official CAMELS-CL basin list, compare against that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import contextily as ctx\n",
    "\n",
    "# Path to the shapefile\n",
    "path_to_shapefile = \"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CL/post_processed/shapefiles/CL/CL_basin_shapes.shp\"\n",
    "\n",
    "# Read the shapefile\n",
    "gdf = gpd.read_file(path_to_shapefile)\n",
    "\n",
    "# Print info\n",
    "print(f\"Number of basins in shapefile: {len(gdf)}\")\n",
    "print(f\"Number of unique gauge_ids: {gdf['gauge_id'].nunique()}\")\n",
    "\n",
    "# Create dictionaries to store relationships\n",
    "parent_to_children = {}\n",
    "child_to_parents = {}\n",
    "\n",
    "# Identify containment relationships\n",
    "for i, basin1 in gdf.iterrows():\n",
    "    for j, basin2 in gdf.iterrows():\n",
    "        if i != j:  # Don't compare basin to itself\n",
    "            # Check if basin1 contains basin2\n",
    "            if basin1.geometry.contains(basin2.geometry.centroid):\n",
    "                # Add to parent-child dictionary\n",
    "                if basin1[\"gauge_id\"] not in parent_to_children:\n",
    "                    parent_to_children[basin1[\"gauge_id\"]] = []\n",
    "                parent_to_children[basin1[\"gauge_id\"]].append(basin2[\"gauge_id\"])\n",
    "\n",
    "                # Add to child-parent dictionary\n",
    "                if basin2[\"gauge_id\"] not in child_to_parents:\n",
    "                    child_to_parents[basin2[\"gauge_id\"]] = []\n",
    "                child_to_parents[basin2[\"gauge_id\"]].append(basin1[\"gauge_id\"])\n",
    "\n",
    "# Identify true subbasins (child basins that don't contain others)\n",
    "all_parents = set(parent_to_children.keys())\n",
    "all_children = set()\n",
    "for children in parent_to_children.values():\n",
    "    all_children.update(children)\n",
    "\n",
    "# True subbasins are children that don't appear as parents\n",
    "true_subbasins = all_children - all_parents\n",
    "\n",
    "# Count how many true subbasins each parent contains\n",
    "parent_subbasin_count = {}\n",
    "for parent, children in parent_to_children.items():\n",
    "    # Count children that are true subbasins\n",
    "    true_children = [child for child in children if child in true_subbasins]\n",
    "    if true_children:\n",
    "        parent_subbasin_count[parent] = len(true_children)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nTotal parent basins: {len(all_parents)}\")\n",
    "print(f\"Total child basins: {len(all_children)}\")\n",
    "print(f\"True subbasins (no children of their own): {len(true_subbasins)}\")\n",
    "\n",
    "# Print the true subbasins\n",
    "print(\"\\nListing true subbasins:\")\n",
    "for basin in sorted(list(true_subbasins)):\n",
    "    print(f\"- {basin}\")\n",
    "\n",
    "# Visualize parent-child relationships\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Plot all basins in light gray\n",
    "gdf.plot(ax=ax, color=\"lightgray\", edgecolor=\"gray\", linewidth=0.3, alpha=0.3)\n",
    "\n",
    "# Create color map for parents with true subbasins\n",
    "parents_with_subbasins = list(parent_subbasin_count.keys())\n",
    "colors = plt.cm.tab20.colors[: len(parents_with_subbasins)]\n",
    "\n",
    "# Plot each parent-child relationship with distinct colors\n",
    "for i, parent_id in enumerate(parents_with_subbasins[:10]):  # Limit to 10 for clarity\n",
    "    # Parent basin with solid color\n",
    "    parent_basin = gdf[gdf[\"gauge_id\"] == parent_id]\n",
    "    parent_basin.plot(ax=ax, color=colors[i], edgecolor=\"black\", linewidth=1, alpha=0.6)\n",
    "\n",
    "    # Child basins that are true subbasins\n",
    "    children = [\n",
    "        child for child in parent_to_children[parent_id] if child in true_subbasins\n",
    "    ]\n",
    "    if children:\n",
    "        child_basins = gdf[gdf[\"gauge_id\"].isin(children)]\n",
    "        child_basins.plot(\n",
    "            ax=ax,\n",
    "            color=colors[i],\n",
    "            edgecolor=\"red\",\n",
    "            linewidth=0.8,\n",
    "            alpha=0.3,\n",
    "            hatch=\"///\",\n",
    "        )\n",
    "\n",
    "    # Annotate parent basin\n",
    "    centroid = parent_basin.geometry.iloc[0].centroid\n",
    "    ax.annotate(\n",
    "        f\"{parent_id}\",\n",
    "        xy=(centroid.x, centroid.y),\n",
    "        ha=\"center\",\n",
    "        fontsize=9,\n",
    "        fontweight=\"bold\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", alpha=0.7),\n",
    "    )\n",
    "\n",
    "# Create a separate visualization showing just the subbasins\n",
    "fig2, ax2 = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Plot all basins in light gray\n",
    "gdf.plot(ax=ax2, color=\"lightgray\", edgecolor=\"gray\", linewidth=0.3, alpha=0.2)\n",
    "\n",
    "# Highlight all true subbasins\n",
    "subbasin_gdf = gdf[gdf[\"gauge_id\"].isin(true_subbasins)]\n",
    "subbasin_gdf.plot(ax=ax2, color=\"red\", edgecolor=\"black\", linewidth=0.5, alpha=0.6)\n",
    "\n",
    "# Add title\n",
    "ax2.set_title(f\"True Subbasins (n={len(true_subbasins)})\", fontsize=14)\n",
    "\n",
    "# Try to add basemap for both plots\n",
    "try:\n",
    "    ctx.add_basemap(ax, crs=gdf.crs)\n",
    "    ctx.add_basemap(ax2, crs=gdf.crs)\n",
    "except Exception as e:\n",
    "    print(f\"Couldn't add basemap: {e}\")\n",
    "\n",
    "# Titles and layout\n",
    "ax.set_title(f\"Parent-Child Basin Relationships (showing 10 parents)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Add shapefiles for CH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gauge_id     ID6     gauge_name           water_body    type country   H1  \\\n",
      "0    2004.0  MuSMur         Murten            Murtensee    lake      CH  218   \n",
      "1    2007.0  LdJLeP        Le_Pont          Lac_de_Joux    lake      CH  204   \n",
      "2    2009.0  RhoPor  Porte_du_Scex                Rhône  stream      CH  574   \n",
      "3    2011.0  RhoSio           Sion                Rhône  stream      CH  576   \n",
      "4    2014.0  ZuSSch     Schmerikon  Zürichsee_(Obersee)    lake      CH  389   \n",
      "\n",
      "    H2     Shape_Leng    Shape_Area  ORIG_FID  \\\n",
      "0  223  147513.769063  2.967222e+08         0   \n",
      "1  209   80843.037249  1.634063e+08         1   \n",
      "2  605  285410.589332  7.042852e+08         2   \n",
      "3  597  247334.395847  1.575511e+09         3   \n",
      "4  390  121687.774151  5.219500e+08         4   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON Z ((7.10753 46.96311 0, 7.10753 46.962...  \n",
      "1  POLYGON Z ((6.34796 46.64424 0, 6.34782 46.643...  \n",
      "2  MULTIPOLYGON Z (((7.00197 46.37201 0, 7.00197 ...  \n",
      "3  POLYGON Z ((7.89701 46.41781 0, 7.89952 46.416...  \n",
      "4  POLYGON Z ((9.00122 47.30551 0, 9.00123 47.305...  \n"
     ]
    }
   ],
   "source": [
    "path_to_shapefiles = \"/Users/cooper/Desktop/CAMELS-CH/data/catchment_delineations/CAMELS_CH_sub_catchments_4326.shp\"\n",
    "\n",
    "# Read the shapefile\n",
    "gdf = gpd.read_file(path_to_shapefiles)\n",
    "print(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             gauge_id                                           geometry\n",
      "0  CH_CH_CH_CH_2004.0  POLYGON Z ((7.10753 46.96311 0, 7.10753 46.962...\n",
      "1  CH_CH_CH_CH_2007.0  POLYGON Z ((6.34796 46.64424 0, 6.34782 46.643...\n",
      "2  CH_CH_CH_CH_2009.0  MULTIPOLYGON Z (((7.00197 46.37201 0, 7.00197 ...\n",
      "3  CH_CH_CH_CH_2011.0  POLYGON Z ((7.89701 46.41781 0, 7.89952 46.416...\n",
      "4  CH_CH_CH_CH_2014.0  POLYGON Z ((9.00122 47.30551 0, 9.00123 47.305...\n",
      "             gauge_id                                           geometry\n",
      "0  CH_CH_CH_CH_2004.0  POLYGON Z ((7.10753 46.96311 0, 7.10753 46.962...\n",
      "1  CH_CH_CH_CH_2007.0  POLYGON Z ((6.34796 46.64424 0, 6.34782 46.643...\n",
      "2  CH_CH_CH_CH_2009.0  MULTIPOLYGON Z (((7.00197 46.37201 0, 7.00197 ...\n",
      "3  CH_CH_CH_CH_2011.0  POLYGON Z ((7.89701 46.41781 0, 7.89952 46.416...\n",
      "4  CH_CH_CH_CH_2014.0  POLYGON Z ((9.00122 47.30551 0, 9.00123 47.305...\n"
     ]
    }
   ],
   "source": [
    "# Add CH_ prefix to gauge_id\n",
    "gdf[\"gauge_id\"] = \"CH_\" + gdf[\"gauge_id\"].astype(str)\n",
    "print(gdf.head())\n",
    "\n",
    "# Only keep gauge_id and geometry\n",
    "gdf = gdf[[\"gauge_id\", \"geometry\"]]\n",
    "print(gdf.head())\n",
    "\n",
    "save_path = \"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CH/post_processed/shapefiles/CH\"\n",
    "save_name = \"CH_basin_shapes.shp\"\n",
    "\n",
    "gdf.to_file(f\"{save_path}/{save_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
