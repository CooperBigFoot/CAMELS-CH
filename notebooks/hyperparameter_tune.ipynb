{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    ")\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from src.data_models.camels_ch import CamelsCH, CamelsCHConfig, get_all_gauge_ids\n",
    "from src.data_models.dataset import HydroDataset\n",
    "from src.data_models.preprocessing import (\n",
    "    scale_time_series,\n",
    "    scale_static_attributes,\n",
    "    inverse_scale_static_attributes,\n",
    "    inverse_scale_time_series,\n",
    ")\n",
    "from src.data_models.caravanify import Caravanify, CaravanifyConfig\n",
    "\n",
    "from utils.metrics import nash_sutcliffe_efficiency\n",
    "from src.data_models.datamodule import HydroDataModule\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.preprocessing.transformers import GroupedTransformer, LogTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.lstm import LitLSTM\n",
    "from src.models.ealstm import LitEALSTM\n",
    "from src.models.TSMixer import LitTSMixer\n",
    "from src.models.evaluators import TSForecastEvaluator\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stations: 3\n"
     ]
    }
   ],
   "source": [
    "config = CaravanifyConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CA/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CA/post_processed/timeseries/csv\",\n",
    "    gauge_id_prefix=\"CA\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "\n",
    "caravan = Caravanify(config)\n",
    "ids_for_training = caravan.get_all_gauge_ids()[:3]\n",
    "\n",
    "print(f\"Total number of stations: {len(ids_for_training)}\")\n",
    "\n",
    "caravan.load_stations(ids_for_training)\n",
    "\n",
    "ts_data = caravan.get_time_series()\n",
    "static_data = caravan.get_static_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data[\"date\"] = pd.to_datetime(ts_data[\"date\"])\n",
    "\n",
    "ts_data[\"julian_day\"] = ts_data[\"date\"].dt.dayofyear\n",
    "\n",
    "ts_columns = [\n",
    "    # \"potential_evaporation_sum_ERA5_LAND\",\n",
    "    # \"potential_evaporation_sum_FAO_PENMAN_MONTEITH\",\n",
    "    \"streamflow\",\n",
    "    # \"julian_day\",\n",
    "    # \"temperature_2m_mean\",\n",
    "    \"total_precipitation_sum\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = ts_columns + [\"gauge_id\", \"date\"]\n",
    "ts_data = ts_data[whole_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "statics_to_keep = [\n",
    "    \"gauge_id\",\n",
    "    \"p_mean\",\n",
    "    \"area\",\n",
    "    \"ele_mt_sav\",\n",
    "    \"high_prec_dur\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"slp_dg_sav\",\n",
    "    \"cly_pc_sav\",\n",
    "    \"aridity_ERA5_LAND\",\n",
    "    \"aridity_FAO_PM\",\n",
    "]\n",
    "\n",
    "static_columns = static_data.columns\n",
    "static_columns = [col for col in list(static_columns) if col in statics_to_keep]\n",
    "\n",
    "static_data = static_data[static_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    col for col in ts_data.columns if col not in [\"gauge_id\", \"date\", \"streamflow\"]\n",
    "]\n",
    "ts_columns = features + [\"streamflow\"]  # Ensure target is not in features\n",
    "\n",
    "# Feature pipeline: log + scale\n",
    "feature_pipeline = Pipeline([(\"log\", LogTransformer()), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "target_pipeline = GroupedTransformer(\n",
    "    Pipeline([(\"log\", LogTransformer()), (\"scaler\", StandardScaler())]),\n",
    "    columns=[\"streamflow\"],\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "static_pipeline = Pipeline([(\"scaler\", StandardScaler())])\n",
    "\n",
    "preprocessing_configs = {\n",
    "    \"features\": {\"pipeline\": feature_pipeline},\n",
    "    \"target\": {\"pipeline\": target_pipeline},\n",
    "    \"static_features\": {\"pipeline\": static_pipeline},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 06:41:57,935] A new study created in memory with name: no-name-41a9d076-6a4d-488a-aa48-d5e35ffd0dc1\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cooper/Desktop/CAMELS-CH/src/data_models/datamodule.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.processed_static[col] = transformed[:, i]\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model         | TSMixer | 851 K  | train\n",
      "1 | mse_criterion | MSELoss | 0      | train\n",
      "--------------------------------------------------\n",
      "851 K     Trainable params\n",
      "0         Non-trainable params\n",
      "851 K     Total params\n",
      "3.404     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 13215 valid sequences\n",
      "Created 606 valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "[I 2025-02-19 06:42:10,634] Trial 0 finished with value: 0.06316959112882614 and parameters: {'batch_size': 126, 'input_length': 53, 'hidden_size': 201}. Best is trial 0 with value: 0.06316959112882614.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/cooper/Desktop/CAMELS-CH/src/data_models/datamodule.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.processed_static[col] = transformed[:, i]\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model         | TSMixer | 564 K  | train\n",
      "1 | mse_criterion | MSELoss | 0      | train\n",
      "--------------------------------------------------\n",
      "564 K     Trainable params\n",
      "0         Non-trainable params\n",
      "564 K     Total params\n",
      "2.259     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 2\n",
      "Created 13272 valid sequences\n",
      "Created 644 valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "[I 2025-02-19 06:42:26,462] Trial 1 finished with value: 0.06423867493867874 and parameters: {'batch_size': 23, 'input_length': 34, 'hidden_size': 197}. Best is trial 0 with value: 0.06316959112882614.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/cooper/Desktop/CAMELS-CH/src/data_models/datamodule.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.processed_static[col] = transformed[:, i]\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model         | TSMixer | 175 K  | train\n",
      "1 | mse_criterion | MSELoss | 0      | train\n",
      "--------------------------------------------------\n",
      "175 K     Trainable params\n",
      "0         Non-trainable params\n",
      "175 K     Total params\n",
      "0.701     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 2\n",
      "Created 13316 valid sequences\n",
      "Created 672 valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "[I 2025-02-19 06:42:35,584] Trial 2 finished with value: 0.06703387200832367 and parameters: {'batch_size': 64, 'input_length': 20, 'hidden_size': 94}. Best is trial 0 with value: 0.06316959112882614.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/cooper/Desktop/CAMELS-CH/src/data_models/datamodule.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.processed_static[col] = transformed[:, i]\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model         | TSMixer | 758 K  | train\n",
      "1 | mse_criterion | MSELoss | 0      | train\n",
      "--------------------------------------------------\n",
      "758 K     Trainable params\n",
      "0         Non-trainable params\n",
      "758 K     Total params\n",
      "3.032     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 2\n",
      "Created 13215 valid sequences\n",
      "Created 606 valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "[I 2025-02-19 06:42:48,666] Trial 3 finished with value: 0.05730516463518143 and parameters: {'batch_size': 58, 'input_length': 53, 'hidden_size': 179}. Best is trial 3 with value: 0.05730516463518143.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/cooper/Desktop/CAMELS-CH/src/data_models/datamodule.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.processed_static[col] = transformed[:, i]\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model         | TSMixer | 753 K  | train\n",
      "1 | mse_criterion | MSELoss | 0      | train\n",
      "--------------------------------------------------\n",
      "753 K     Trainable params\n",
      "0         Non-trainable params\n",
      "753 K     Total params\n",
      "3.013     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 2\n",
      "Created 13209 valid sequences\n",
      "Created 602 valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "[I 2025-02-19 06:43:06,625] Trial 4 finished with value: 0.05534825474023819 and parameters: {'batch_size': 17, 'input_length': 55, 'hidden_size': 172}. Best is trial 4 with value: 0.05534825474023819.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/cooper/Desktop/CAMELS-CH/src/data_models/datamodule.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.processed_static[col] = transformed[:, i]\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model         | TSMixer | 1.1 M  | train\n",
      "1 | mse_criterion | MSELoss | 0      | train\n",
      "--------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.325     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 2\n",
      "Created 13209 valid sequences\n",
      "Created 602 valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "[I 2025-02-19 06:43:25,599] Trial 5 finished with value: 0.058484047651290894 and parameters: {'batch_size': 17, 'input_length': 55, 'hidden_size': 247}. Best is trial 4 with value: 0.05534825474023819.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/cooper/Desktop/CAMELS-CH/src/data_models/datamodule.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.processed_static[col] = transformed[:, i]\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model         | TSMixer | 254 K  | train\n",
      "1 | mse_criterion | MSELoss | 0      | train\n",
      "--------------------------------------------------\n",
      "254 K     Trainable params\n",
      "0         Non-trainable params\n",
      "254 K     Total params\n",
      "1.019     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 2\n",
      "Created 13275 valid sequences\n",
      "Created 646 valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "[I 2025-02-19 06:43:38,847] Trial 6 finished with value: 0.05589953437447548 and parameters: {'batch_size': 17, 'input_length': 33, 'hidden_size': 91}. Best is trial 4 with value: 0.05534825474023819.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/cooper/Desktop/CAMELS-CH/src/data_models/datamodule.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.processed_static[col] = transformed[:, i]\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model         | TSMixer | 701 K  | train\n",
      "1 | mse_criterion | MSELoss | 0      | train\n",
      "--------------------------------------------------\n",
      "701 K     Trainable params\n",
      "0         Non-trainable params\n",
      "701 K     Total params\n",
      "2.805     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 2\n",
      "Created 13203 valid sequences\n",
      "Created 598 valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "[I 2025-02-19 06:43:53,822] Trial 7 finished with value: 0.06362254172563553 and parameters: {'batch_size': 22, 'input_length': 57, 'hidden_size': 155}. Best is trial 4 with value: 0.05534825474023819.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/cooper/Desktop/CAMELS-CH/src/data_models/datamodule.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.processed_static[col] = transformed[:, i]\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model         | TSMixer | 378 K  | train\n",
      "1 | mse_criterion | MSELoss | 0      | train\n",
      "--------------------------------------------------\n",
      "378 K     Trainable params\n",
      "0         Non-trainable params\n",
      "378 K     Total params\n",
      "1.513     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 2\n",
      "Created 13224 valid sequences\n",
      "Created 612 valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "[I 2025-02-19 06:44:03,660] Trial 8 finished with value: 0.06368408352136612 and parameters: {'batch_size': 121, 'input_length': 50, 'hidden_size': 94}. Best is trial 4 with value: 0.05534825474023819.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/cooper/Desktop/CAMELS-CH/src/data_models/datamodule.py:344: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.processed_static[col] = transformed[:, i]\n",
      "\n",
      "  | Name          | Type    | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model         | TSMixer | 446 K  | train\n",
      "1 | mse_criterion | MSELoss | 0      | train\n",
      "--------------------------------------------------\n",
      "446 K     Trainable params\n",
      "0         Non-trainable params\n",
      "446 K     Total params\n",
      "1.785     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 2\n",
      "Created 13320 valid sequences\n",
      "Created 674 valid sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "[I 2025-02-19 06:44:15,625] Trial 9 finished with value: 0.057196177542209625 and parameters: {'batch_size': 36, 'input_length': 19, 'hidden_size': 250}. Best is trial 4 with value: 0.05534825474023819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 17, 'input_length': 55, 'hidden_size': 172}\n",
      "Best validation loss: 0.05534825474023819\n",
      "Study statistics: \n",
      "  Number of finished trials:  10\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  10\n"
     ]
    }
   ],
   "source": [
    "output_length = 10\n",
    "static_columns = [c for c in static_columns if c not in [\"gauge_id\"]]\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 128)\n",
    "    input_length = trial.suggest_int(\"input_length\", 14, 60)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 32, 256)\n",
    "\n",
    "    # Create data module with the trial's batch size and input length\n",
    "    data_module = HydroDataModule(\n",
    "        time_series_df=ts_data,\n",
    "        static_df=static_data,\n",
    "        group_identifier=\"gauge_id\",\n",
    "        preprocessing_config=preprocessing_configs,\n",
    "        batch_size=batch_size,  # Use trial's batch size\n",
    "        input_length=input_length,  # Use trial's input length\n",
    "        output_length=output_length,\n",
    "        num_workers=4,\n",
    "        features=ts_columns,\n",
    "        static_features=static_columns,\n",
    "        target=\"streamflow\",\n",
    "        min_train_years=2,\n",
    "        val_years=1,\n",
    "        test_years=3,\n",
    "        max_missing_pct=10,\n",
    "    )\n",
    "\n",
    "    # Create model with trial's hidden size\n",
    "    model = LitTSMixer(\n",
    "        input_len=input_length,  # Match data module's input length\n",
    "        output_len=output_length,\n",
    "        input_size=len(ts_columns),\n",
    "        static_size=len(static_columns),\n",
    "        hidden_size=hidden_size,  # Use trial's hidden size\n",
    "    )\n",
    "\n",
    "    # Configure trainer with early stopping\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=1,  # Keep this low for initial testing\n",
    "        accelerator=\"cpu\",\n",
    "        devices=1,\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")],\n",
    "        enable_progress_bar=False,  # Reduce output clutter during optimization\n",
    "    )\n",
    "\n",
    "    # Train and get the best validation loss\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()\n",
    "\n",
    "\n",
    "# Create a study object and specify the direction of optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "# Run the optimization\n",
    "study.optimize(objective, n_trials=10)  # Start with 10 trials for testing\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best validation loss:\", study.best_value)\n",
    "\n",
    "# You can also print a summary of the optimization\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\n",
    "    \"  Number of pruned trials: \",\n",
    "    len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),\n",
    ")\n",
    "print(\n",
    "    \"  Number of complete trials: \",\n",
    "    len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
