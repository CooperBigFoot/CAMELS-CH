{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    ")\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from src.data_models.camels_ch import CamelsCH, CamelsCHConfig, get_all_gauge_ids\n",
    "from src.data_models.dataset import HydroDataset\n",
    "from src.data_models.preprocessing import (\n",
    "    scale_time_series,\n",
    "    scale_static_attributes,\n",
    "    inverse_scale_static_attributes,\n",
    "    inverse_scale_time_series,\n",
    ")\n",
    "from src.data_models.caravanify import Caravanify, CaravanifyConfig\n",
    "\n",
    "from utils.metrics import nash_sutcliffe_efficiency\n",
    "from src.data_models.datamodule import HydroTransferDataModule, HydroDataModule\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from src.preprocessing.grouped import GroupedTransformer\n",
    "from src.preprocessing.log_scale import LogTransformer\n",
    "from src.preprocessing.standard_scale import StandardScaleTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.lstm import LitLSTM\n",
    "from src.models.ealstm import LitEALSTM\n",
    "from src.models.TSMixer import LitTSMixer, TSMixerConfig\n",
    "from src.models.TSMixerDomainAdaptation import LitTSMixerDomainAdaptation\n",
    "from src.models.evaluators import TSForecastEvaluator\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stations: 3\n"
     ]
    }
   ],
   "source": [
    "# Configuration for loading Central Asian (CA) hydrology data\n",
    "CA_config = CaravanifyConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CA/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CA/post_processed/timeseries/csv\",\n",
    "    gauge_id_prefix=\"CA\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "# Initialize Caravan data loader and load first 3 stations for training\n",
    "CA_caravan = Caravanify(CA_config)\n",
    "ids_for_training = CA_caravan.get_all_gauge_ids()[14:17]\n",
    "print(f\"Total number of stations: {len(ids_for_training)}\")\n",
    "CA_caravan.load_stations(ids_for_training)\n",
    "\n",
    "# Get time series and static data\n",
    "CA_ts_data = CA_caravan.get_time_series()\n",
    "CA_static_data = CA_caravan.get_static_attributes()\n",
    "\n",
    "# Process time series data\n",
    "CA_ts_data[\"date\"] = pd.to_datetime(CA_ts_data[\"date\"])\n",
    "CA_ts_data[\"julian_day\"] = CA_ts_data[\"date\"].dt.dayofyear\n",
    "\n",
    "# Select relevant time series features\n",
    "ts_columns = [\"streamflow\", \"total_precipitation_sum\"]\n",
    "CA_ts_data = CA_ts_data[ts_columns + [\"gauge_id\", \"date\"]]\n",
    "\n",
    "# Select relevant static features that characterize catchment properties\n",
    "static_columns = [\n",
    "    \"gauge_id\", \"p_mean\", \"area\", \"ele_mt_sav\", \"high_prec_dur\",\n",
    "    \"frac_snow\", \"high_prec_freq\", \"slp_dg_sav\", \"cly_pc_sav\",\n",
    "    \"aridity_ERA5_LAND\", \"aridity_FAO_PM\"\n",
    "]\n",
    "CA_static_data = CA_static_data[static_columns]\n",
    "\n",
    "# Separate features from target variable\n",
    "features = [col for col in CA_ts_data.columns if col not in [\n",
    "    \"gauge_id\", \"date\", \"streamflow\"]]\n",
    "ts_columns = features + [\"streamflow\"]\n",
    "\n",
    "feature_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaleTransformer(columns=features))\n",
    "])\n",
    "\n",
    "target_pipeline = GroupedTransformer(\n",
    "    Pipeline([\n",
    "        (\"scaler\", StandardScaleTransformer(columns=[\"streamflow\"]))\n",
    "    ]),\n",
    "    columns=[\"streamflow\"],\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "static_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaleTransformer(columns=static_columns[1:]))\n",
    "])\n",
    "\n",
    "# Define preprocessing configurations\n",
    "preprocessing_configs = {\n",
    "    \"features\": {\n",
    "        \"pipeline\": feature_pipeline\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"pipeline\": target_pipeline\n",
    "    },\n",
    "    \"static_features\": {\n",
    "        \"pipeline\": static_pipeline\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 3\n",
      "Domain target: Created 18954 valid sequences from 3 catchments\n",
      "Domain target: Created 876 valid sequences from 3 catchments\n",
      "Domain target: Created 2855 valid sequences from 3 catchments\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "output_length = 10\n",
    "input_length = 64\n",
    "hidden_size = 32\n",
    "\n",
    "# Create data module with the trial's batch size and input length\n",
    "CA_data_module = HydroDataModule(\n",
    "    time_series_df=CA_ts_data,\n",
    "    static_df=CA_static_data,\n",
    "    group_identifier=\"gauge_id\",\n",
    "    preprocessing_config=preprocessing_configs,\n",
    "    batch_size=batch_size,  # Use trial's batch size\n",
    "    input_length=input_length,  # Use trial's input length\n",
    "    output_length=output_length,\n",
    "    num_workers=4,\n",
    "    features=ts_columns,\n",
    "    static_features=static_columns,\n",
    "    target=\"streamflow\",\n",
    "    min_train_years=2,\n",
    "    val_years=1,\n",
    "    test_years=3,\n",
    "    max_missing_pct=10,\n",
    "    domain_id=\"target\",\n",
    ")\n",
    "\n",
    "CA_data_module.prepare_data()\n",
    "CA_data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switzerland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stations: 3\n"
     ]
    }
   ],
   "source": [
    "# Configuration for loading Central Asian (CA) hydrology data\n",
    "CH_config = CaravanifyConfig(\n",
    "    attributes_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CH/post_processed/attributes\",\n",
    "    timeseries_dir=\"/Users/cooper/Desktop/CAMELS-CH/data/CARAVANIFY/CH/post_processed/timeseries/csv\",\n",
    "    gauge_id_prefix=\"CH\",\n",
    "    use_hydroatlas_attributes=True,\n",
    "    use_caravan_attributes=True,\n",
    "    use_other_attributes=True,\n",
    ")\n",
    "\n",
    "# Initialize Caravan data loader and load first 3 stations for training\n",
    "CH_caravan = Caravanify(CH_config)\n",
    "ids_for_training = CH_caravan.get_all_gauge_ids()[14:17]\n",
    "print(f\"Total number of stations: {len(ids_for_training)}\")\n",
    "CH_caravan.load_stations(ids_for_training)\n",
    "\n",
    "# Get time series and static data\n",
    "CH_ts_data = CH_caravan.get_time_series()\n",
    "CH_static_data = CH_caravan.get_static_attributes()\n",
    "\n",
    "# Process time series data\n",
    "CH_ts_data[\"date\"] = pd.to_datetime(CH_ts_data[\"date\"])\n",
    "CH_ts_data[\"julian_day\"] = CH_ts_data[\"date\"].dt.dayofyear\n",
    "\n",
    "# Select relevant time series features\n",
    "ts_columns = [\"streamflow\", \"total_precipitation_sum\"]\n",
    "CH_ts_data = CH_ts_data[ts_columns + [\"gauge_id\", \"date\"]]\n",
    "\n",
    "# Select relevant static features that characterize catchment properties\n",
    "static_columns = [\n",
    "    \"gauge_id\", \"p_mean\", \"area\", \"ele_mt_sav\", \"high_prec_dur\",\n",
    "    \"frac_snow\", \"high_prec_freq\", \"slp_dg_sav\", \"cly_pc_sav\",\n",
    "    \"aridity_ERA5_LAND\", \"aridity_FAO_PM\"\n",
    "]\n",
    "CH_static_data = CH_static_data[static_columns]\n",
    "\n",
    "# Separate features from target variable\n",
    "features = [col for col in CH_ts_data.columns if col not in [\n",
    "    \"gauge_id\", \"date\", \"streamflow\"]]\n",
    "ts_columns = features + [\"streamflow\"]\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "feature_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaleTransformer(columns=features))\n",
    "])\n",
    "\n",
    "target_pipeline = GroupedTransformer(\n",
    "    Pipeline([\n",
    "        (\"scaler\", StandardScaleTransformer(columns=[\"streamflow\"]))\n",
    "    ]),\n",
    "    columns=[\"streamflow\"],\n",
    "    group_identifier=\"gauge_id\",\n",
    ")\n",
    "\n",
    "static_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaleTransformer(columns=static_columns[1:]))\n",
    "])\n",
    "\n",
    "# Define preprocessing configurations\n",
    "preprocessing_configs = {\n",
    "    \"features\": {\n",
    "        \"pipeline\": feature_pipeline\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"pipeline\": target_pipeline\n",
    "    },\n",
    "    \"static_features\": {\n",
    "        \"pipeline\": static_pipeline\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original basins: 3\n",
      "Retained basins: 3\n",
      "Domain source: Created 39225 valid sequences from 3 catchments\n",
      "Domain source: Created 876 valid sequences from 3 catchments\n",
      "Domain source: Created 3069 valid sequences from 3 catchments\n"
     ]
    }
   ],
   "source": [
    "CH_data_module = HydroDataModule(\n",
    "    time_series_df=CH_ts_data,\n",
    "    static_df=CH_static_data,\n",
    "    group_identifier=\"gauge_id\",\n",
    "    preprocessing_config=preprocessing_configs,\n",
    "    batch_size=batch_size,  # Use trial's batch size\n",
    "    input_length=input_length,  # Use trial's input length\n",
    "    output_length=output_length,\n",
    "    num_workers=4,\n",
    "    features=ts_columns,\n",
    "    static_features=static_columns,\n",
    "    target=\"streamflow\",\n",
    "    min_train_years=2,\n",
    "    val_years=1,\n",
    "    test_years=3,\n",
    "    max_missing_pct=10,\n",
    "    domain_id=\"source\",\n",
    ")\n",
    "\n",
    "CH_data_module.prepare_data()\n",
    "CH_data_module.setup()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing combined DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'tuple'>\n",
      "\n",
      "Source batch keys: dict_keys(['X', 'y', 'static', 'domain_id', 'gauge_id', 'slice_idx'])\n",
      "Source X shape: torch.Size([128, 64, 2])\n",
      "Source static shape: torch.Size([128, 10])\n",
      "Source y shape: torch.Size([128, 10])\n",
      "\n",
      "Target batch keys: dict_keys(['X', 'y', 'static', 'domain_id', 'gauge_id', 'slice_idx'])\n",
      "Target X shape: torch.Size([128, 64, 2])\n",
      "Target static shape: torch.Size([128, 10])\n",
      "Target y shape: torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "# Create transfer datamodule\n",
    "transfer_dm = HydroTransferDataModule(\n",
    "    source_datamodule=CA_data_module,\n",
    "    target_datamodule=CH_data_module,\n",
    "    num_workers=4,\n",
    "    mode=\"min_size\",\n",
    ")\n",
    "\n",
    "# Show one batch of data\n",
    "batch = next(iter(transfer_dm.train_dataloader()))\n",
    "print(f\"Batch type: {type(batch)}\")\n",
    "\n",
    "# Since it's a tuple, we need to access elements by index\n",
    "data_dict, _, _ = batch\n",
    "source_batch = data_dict[\"source\"]\n",
    "target_batch = data_dict[\"target\"]\n",
    "\n",
    "# Print source batch information\n",
    "print(\"\\nSource batch keys:\", source_batch.keys())\n",
    "print(\"Source X shape:\", source_batch[\"X\"].shape)\n",
    "print(\"Source static shape:\", source_batch[\"static\"].shape)\n",
    "print(\"Source y shape:\", source_batch[\"y\"].shape)\n",
    "\n",
    "# Print target batch information\n",
    "print(\"\\nTarget batch keys:\", target_batch.keys())\n",
    "print(\"Target X shape:\", target_batch[\"X\"].shape)\n",
    "print(\"Target static shape:\", target_batch[\"static\"].shape)\n",
    "print(\"Target y shape:\", target_batch[\"y\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name                 | Type                | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | model                | TSMixer             | 27.2 K | train\n",
      "1 | domain_discriminator | DomainDiscriminator | 2.1 K  | train\n",
      "2 | mse_criterion        | MSELoss             | 0      | train\n",
      "3 | domain_criterion     | BCELoss             | 0      | train\n",
      "---------------------------------------------------------------------\n",
      "29.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.3 K    Total params\n",
      "0.117     Total estimated model params size (MB)\n",
      "104       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80e570eef0342e8b8c7d79d355d1f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270a78d9663e4405a40fab7e3db89a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8e227ecc6d4f4695b2ab5a8f5fe7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79875c4158546de8157732168bec7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 575, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
      "    self.advance()\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 150, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 320, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 192, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 270, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 171, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py\", line 1302, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py\", line 154, in step\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 123, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 493, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/torch/optim/adam.py\", line 223, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 109, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 146, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 140, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 241, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 323, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py\", line 213, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 73, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py\", line 1097, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/y6/kqwqph4s3sj7hkxryrly5y6r0000gn/T/ipykernel_87155/1720479267.py\", line 28, in <module>\n",
      "    trainer.fit(model, transfer_dm)\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 539, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 64, in _call_and_handle_interrupt\n",
      "    exit(1)\n",
      "    ^^^^\n",
      "NameError: name 'exit' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 2170, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1214, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1160, in get_records\n",
      "    max_len = get_line_number_of_frame(cf.tb_frame)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 184, in get_line_number_of_frame\n",
      "    return count_lines_in_py_file(filename)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 150, in count_lines_in_py_file\n",
      "    s = sum(1 for line in file)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 150, in <genexpr>\n",
      "    s = sum(1 for line in file)\n",
      "                          ^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 87202) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/asyncio/base_events.py\", line 640, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/asyncio/base_events.py\", line 1954, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/selectors.py\", line 566, in select\n",
      "    kev_list = self._selector.control(None, max_ev, timeout)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cooper/Desktop/CAMELS-CH/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 87207) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from src.models.TSMixerDomainAdaptation import TSMixerDomainAdaptationConfig\n",
    "\n",
    "# 1. Create the domain adaptation config\n",
    "domain_adaptation_config = TSMixerDomainAdaptationConfig(\n",
    "    input_len=input_length,\n",
    "    input_size=2,\n",
    "    output_len=output_length,\n",
    "    static_size=10,\n",
    "    hidden_size=hidden_size,\n",
    "    lambda_adv=1.0,\n",
    "    domain_loss_weight=0.1,\n",
    "    group_identifier=\"gauge_id\",\n",
    "    lambda_init_value=0,\n",
    ")\n",
    "\n",
    "# 2. Initialize the model with domain adaptation config\n",
    "model = LitTSMixerDomainAdaptation(config=domain_adaptation_config)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5)],\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "trainer.fit(model, transfer_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, CA_data_module)\n",
    "raw_results = model.test_results\n",
    "\n",
    "# Create evaluator and get metrics\n",
    "evaluator = TSForecastEvaluator(\n",
    "    CA_data_module, horizons=list(range(1, model.config.output_len + 1))\n",
    ")\n",
    "results_df, overall_metrics, basin_metrics = evaluator.evaluate(raw_results)\n",
    "\n",
    "# Get overall summary\n",
    "overall_summary = evaluator.summarize_metrics(overall_metrics)\n",
    "\n",
    "# Get per-basin summary\n",
    "basin_summary = evaluator.summarize_metrics(basin_metrics, per_basin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_metric_summary(\n",
    "    summary_df: pd.DataFrame, metric: str, per_basin: bool = False, figsize=(10, 6)\n",
    "):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    if per_basin:\n",
    "        df_plot = summary_df[metric].unstack(level=0)\n",
    "\n",
    "        # Sort basins based on first horizon values\n",
    "        first_horizon_values = df_plot.iloc[0]\n",
    "        sorted_basins = first_horizon_values.sort_values(ascending=False).index\n",
    "        df_plot = df_plot[sorted_basins]\n",
    "\n",
    "        sns.barplot(\n",
    "            data=df_plot.melt(ignore_index=False).reset_index(),\n",
    "            x=\"horizon\",\n",
    "            y=\"value\",\n",
    "            hue=\"basin_id\",\n",
    "            palette=\"Blues\",\n",
    "        )\n",
    "        plt.title(f\"{metric} by Basin and Horizon\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", title=\"Basin ID\")\n",
    "\n",
    "    else:\n",
    "        ax = sns.barplot(x=summary_df.index, y=summary_df[metric], color=\"steelblue\")\n",
    "        plt.title(f\"Overall {metric} by Horizon\")\n",
    "\n",
    "        for i, v in enumerate(summary_df[metric]):\n",
    "            ax.text(i, v, f\"{v:.2f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    plt.xlabel(\"Forecast Horizon\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "plot_metric_summary(overall_summary, \"NSE\")  # Plot overall NSE\n",
    "plot_metric_summary(\n",
    "    basin_summary, \"NSE\", per_basin=True, figsize=(12, 6)\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with lambda set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from src.models.TSMixerDomainAdaptation import TSMixerDomainAdaptationConfig\n",
    "\n",
    "# 1. Create the domain adaptation config\n",
    "domain_adaptation_config = TSMixerDomainAdaptationConfig(\n",
    "    input_len=input_length,\n",
    "    input_size=2,\n",
    "    output_len=output_length,\n",
    "    static_size=10,\n",
    "    hidden_size=hidden_size,\n",
    "    lambda_adv=0.0,\n",
    "    domain_loss_weight=0.0,\n",
    "    group_identifier=\"gauge_id\"\n",
    ")\n",
    "\n",
    "# 2. Initialize the model with domain adaptation config\n",
    "model = LitTSMixerDomainAdaptation(config=domain_adaptation_config)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=3)],\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "trainer.fit(model, transfer_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, CA_data_module)\n",
    "raw_results = model.test_results\n",
    "\n",
    "# Create evaluator and get metrics\n",
    "evaluator = TSForecastEvaluator(\n",
    "    CA_data_module, horizons=list(range(1, model.config.output_len + 1))\n",
    ")\n",
    "results_df, overall_metrics, basin_metrics = evaluator.evaluate(raw_results)\n",
    "\n",
    "# Get overall summary\n",
    "overall_summary = evaluator.summarize_metrics(overall_metrics)\n",
    "\n",
    "# Get per-basin summary\n",
    "basin_summary = evaluator.summarize_metrics(basin_metrics, per_basin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_metric_summary(\n",
    "    summary_df: pd.DataFrame, metric: str, per_basin: bool = False, figsize=(10, 6)\n",
    "):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    if per_basin:\n",
    "        df_plot = summary_df[metric].unstack(level=0)\n",
    "\n",
    "        # Sort basins based on first horizon values\n",
    "        first_horizon_values = df_plot.iloc[0]\n",
    "        sorted_basins = first_horizon_values.sort_values(ascending=False).index\n",
    "        df_plot = df_plot[sorted_basins]\n",
    "\n",
    "        sns.barplot(\n",
    "            data=df_plot.melt(ignore_index=False).reset_index(),\n",
    "            x=\"horizon\",\n",
    "            y=\"value\",\n",
    "            hue=\"basin_id\",\n",
    "            palette=\"Blues\",\n",
    "        )\n",
    "        plt.title(f\"{metric} by Basin and Horizon\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", title=\"Basin ID\")\n",
    "\n",
    "    else:\n",
    "        ax = sns.barplot(x=summary_df.index, y=summary_df[metric], color=\"steelblue\")\n",
    "        plt.title(f\"Overall {metric} by Horizon\")\n",
    "\n",
    "        for i, v in enumerate(summary_df[metric]):\n",
    "            ax.text(i, v, f\"{v:.2f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    plt.xlabel(\"Forecast Horizon\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "plot_metric_summary(overall_summary, \"NSE\")  # Plot overall NSE\n",
    "plot_metric_summary(\n",
    "    basin_summary, \"NSE\", per_basin=True, figsize=(12, 6)\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
