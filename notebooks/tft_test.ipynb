{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "from typing import Optional\n",
    "\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available (use pytorch)\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASIN_ID = 3033\n",
    "BASE_DATA_DIR = \"/Users/cooper/Desktop/CAMELS-CH/data/timeseries\"\n",
    "OBSERVATION_SUBDIR = \"observation_based\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(basin_id: int = BASIN_ID) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Constructs path to CAMELS-CH observation data file.\n",
    "\n",
    "    Args:\n",
    "        basin_id: ID of the basin to load\n",
    "    Returns:\n",
    "        Full path to data file if exists, None otherwise\n",
    "    \"\"\"\n",
    "    data_directory = os.path.join(BASE_DATA_DIR, OBSERVATION_SUBDIR)\n",
    "    data_file = f\"CAMELS_CH_obs_based_{basin_id}.csv\"\n",
    "    path_to_data = os.path.join(data_directory, data_file)\n",
    "\n",
    "    return path_to_data if os.path.exists(path_to_data) else None\n",
    "\n",
    "\n",
    "def preprocess_streamflow_data(path_to_data: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    streamflow_timeseries = pd.read_csv(path_to_data, index_col=0, parse_dates=True)\n",
    "    streamflow_timeseries = streamflow_timeseries.dropna(subset=[\"discharge_spec(mm/d)\"])\n",
    "    \n",
    "    target = streamflow_timeseries[\"discharge_spec(mm/d)\"]\n",
    "    covariates = streamflow_timeseries[[\n",
    "        \"precipitation(mm/d)\",\n",
    "        \"temperature_min(degC)\",\n",
    "        \"temperature_mean(degC)\",\n",
    "        \"temperature_max(degC)\",\n",
    "    ]]\n",
    "\n",
    "    # Create scalers once\n",
    "    covariate_scaler = StandardScaler()\n",
    "    target_scaler = StandardScaler()\n",
    "\n",
    "    covariates_scaled = pd.DataFrame(\n",
    "        covariate_scaler.fit_transform(covariates),\n",
    "        index=covariates.index,\n",
    "        columns=covariates.columns,\n",
    "    )\n",
    "\n",
    "    target_scaled = pd.Series(\n",
    "        target_scaler.fit_transform(target.values.reshape(-1, 1)).flatten(),\n",
    "        index=target.index,\n",
    "        name=target.name,\n",
    "    )\n",
    "    return covariates_scaled, target_scaled, target_scaler  # Return scaler for inverse transform if needed\n",
    "\n",
    "path_to_data = get_data_path()\n",
    "covariates, target, target_scaler = preprocess_streamflow_data(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "target_doy = target.copy()\n",
    "target_doy.index = target_doy.index.dayofyear\n",
    "\n",
    "# Calculate statistics by day of year\n",
    "stats = target_doy.groupby(target_doy.index).agg([\"median\", \"std\", \"mean\"])\n",
    "median_flow = stats[\"median\"]\n",
    "std_flow = stats[\"std\"]\n",
    "mean_flow = stats[\"mean\"]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot individual years\n",
    "for year in target.index.year.unique():\n",
    "    year_data = target[target.index.year == year]\n",
    "    year_data.index = year_data.index.dayofyear\n",
    "    plt.plot(year_data, color=\"gray\", alpha=0.2, label=\"_nolegend_\")\n",
    "\n",
    "# Plot std dev range\n",
    "plt.fill_between(\n",
    "    median_flow.index,\n",
    "    median_flow - std_flow,\n",
    "    median_flow + std_flow,\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    "    label=\"Std Dev Range\",\n",
    ")\n",
    "\n",
    "# Plot median\n",
    "plt.plot(median_flow, color=\"blue\", linewidth=2, label=\"Median\")\n",
    "\n",
    "# Plot mean\n",
    "plt.plot(mean_flow, color=\"red\", linewidth=2, label=\"Mean\")\n",
    "\n",
    "plt.title(\"Daily Streamflow by Year\")\n",
    "plt.xlabel(\"Day of Year\")\n",
    "plt.ylabel(\"Discharge (mm/day)\")\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_doy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
