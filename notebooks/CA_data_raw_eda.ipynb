{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare gauge metadata info for Caravanification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_kgz_basins = \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/basin_outline/kyrgyzstan/HRU_KRG_ML_MODEL_BASINS_1d.shp\"\n",
    "path_to_tjik_basins = \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/basin_outline/tajikistan/HRU_TAJIK_ML_MODEL_BASINS_1d.shp\"\n",
    "\n",
    "kgz_basins = gpd.read_file(path_to_kgz_basins)\n",
    "tjik_basins = gpd.read_file(path_to_tjik_basins)\n",
    "\n",
    "# Print the crs\n",
    "print(kgz_basins.crs)\n",
    "print(tjik_basins.crs)\n",
    "\n",
    "# To ESPG 4326\n",
    "kgz_basins = kgz_basins.to_crs(epsg=4326)\n",
    "tjik_basins = tjik_basins.to_crs(epsg=4326)\n",
    "\n",
    "# Plot one on top of the other\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "kgz_basins.plot(ax=ax, color=\"purple\", edgecolor=\"black\", alpha=0.5)\n",
    "tjik_basins.plot(ax=ax, color=\"blue\", edgecolor=\"black\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pgkg = \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/CA-discharge.gpkg\"\n",
    "\n",
    "gpkg = gpd.read_file(path_to_pgkg)\n",
    "\n",
    "# Create lat/lon mapping dictionaries\n",
    "lat_dict = dict(zip(gpkg[\"CODE\"], gpkg[\"LAT\"]))\n",
    "lon_dict = dict(zip(gpkg[\"CODE\"], gpkg[\"LON\"]))\n",
    "country_dict = dict(zip(gpkg[\"CODE\"], gpkg[\"COUNTRY\"]))\n",
    "\n",
    "# Add lat/lon columns to basin dataframes\n",
    "kgz_basins[\"LAT\"] = kgz_basins[\"CODE\"].map(lat_dict)\n",
    "kgz_basins[\"LON\"] = kgz_basins[\"CODE\"].map(lon_dict)\n",
    "kgz_basins[\"COUNTRY\"] = kgz_basins[\"CODE\"].map(country_dict)\n",
    "\n",
    "tjik_basins[\"LAT\"] = tjik_basins[\"CODE\"].map(lat_dict)\n",
    "tjik_basins[\"LON\"] = tjik_basins[\"CODE\"].map(lon_dict)\n",
    "tjik_basins[\"COUNTRY\"] = tjik_basins[\"CODE\"].map(country_dict)\n",
    "\n",
    "column_rename = {\n",
    "    \"CODE\": \"gauge_id\",\n",
    "    \"LAT\": \"gauge_lat\",\n",
    "    \"LON\": \"gauge_lon\",\n",
    "    \"COUNTRY\": \"country\",\n",
    "}\n",
    "\n",
    "country_mapping = {\n",
    "    \"KYG\": \"Kyrgyzstan\",\n",
    "    \"TAJ\": \"Tajikistan\",\n",
    "}\n",
    "\n",
    "kgz_basins = kgz_basins.rename(columns=column_rename)\n",
    "tjik_basins = tjik_basins.rename(columns=column_rename)\n",
    "\n",
    "kgz_basins[\"country\"] = kgz_basins[\"country\"].map(country_mapping)\n",
    "tjik_basins[\"country\"] = tjik_basins[\"country\"].map(country_mapping)\n",
    "\n",
    "# Create gauge_name from gauge_id and country\n",
    "kgz_basins[\"gauge_name\"] = (\n",
    "    kgz_basins[\"gauge_id\"].astype(str) + \"_\" + kgz_basins[\"country\"]\n",
    ")\n",
    "tjik_basins[\"gauge_name\"] = (\n",
    "    tjik_basins[\"gauge_id\"].astype(str) + \"_\" + tjik_basins[\"country\"]\n",
    ")\n",
    "\n",
    "columns_to_keep = [\"gauge_id\", \"gauge_lat\", \"gauge_lon\", \"country\", \"gauge_name\"]\n",
    "kgz_basins = kgz_basins[columns_to_keep]\n",
    "tjik_basins = tjik_basins[columns_to_keep]\n",
    "\n",
    "# Merge the two geo dataframes\n",
    "merged_basins = pd.concat([kgz_basins, tjik_basins])\n",
    "merged_basins = merged_basins.dropna()\n",
    "\n",
    "# Set index to gauge_id\n",
    "merged_basins = merged_basins.set_index(\"gauge_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_basins.to_csv(\n",
    "    \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/CA_gauge_metadata_info.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare streamflow data for Caravanification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_kgz_streamflow = \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/discharge/KYRGYZSTAN_streamflow.csv\"\n",
    "path_to_tjik_streamflow = \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/discharge/TAJIKISTAN_streamflow.csv\"\n",
    "\n",
    "kgz_streamflow = pd.read_csv(path_to_kgz_streamflow)\n",
    "tjik_streamflow = pd.read_csv(path_to_tjik_streamflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_discharge_to_mm_per_day(discharge: float, area: float) -> float:\n",
    "    \"\"\"Takes discharge in m3/d and converts to mm/d\n",
    "\n",
    "    Parameters:\n",
    "        discharge (float): discharge in m3/d\n",
    "        area (float): area in km2\n",
    "\n",
    "    Returns:\n",
    "        float: discharge in mm/d\n",
    "    \"\"\"\n",
    "\n",
    "    return discharge / (area * 1000)\n",
    "\n",
    "\n",
    "path_to_kgz_basins = \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/basin_outline/kyrgyzstan/HRU_KRG_ML_MODEL_BASINS_1d.shp\"\n",
    "path_to_tjik_basins = \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/basin_outline/tajikistan/HRU_TAJIK_ML_MODEL_BASINS_1d.shp\"\n",
    "\n",
    "kgz_basins = gpd.read_file(path_to_kgz_basins)\n",
    "tjik_basins = gpd.read_file(path_to_tjik_basins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tjik_streamflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgz_streamflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_discharge_data(streamflow_df, basins_gdf):\n",
    "    # Convert to projected CRS (e.g. UTM) for accurate area calculation\n",
    "    basins_proj = basins_gdf.to_crs(epsg=32642)  # UTM zone 42N for Central Asia\n",
    "\n",
    "    basins_df = basins_proj[[\"CODE\", \"geometry\"]].copy()\n",
    "    basins_df[\"CODE\"] = basins_df[\"CODE\"].astype(int)\n",
    "    basins_df[\"area_km2\"] = basins_df.geometry.area / 1e6\n",
    "\n",
    "    print(f\"Min area: {min(basins_df['area_km2'])} km²\")\n",
    "    print(f\"Max area: {max(basins_df['area_km2'])} km²\")\n",
    "\n",
    "    streamflow_df[\"code\"] = streamflow_df[\"code\"].astype(int)\n",
    "    df = streamflow_df.merge(\n",
    "        basins_df[[\"CODE\", \"area_km2\"]], left_on=\"code\", right_on=\"CODE\"\n",
    "    )\n",
    "\n",
    "    df[\"discharge_spec\"] = df.apply(\n",
    "        lambda x: convert_discharge_to_mm_per_day(\n",
    "            x[\"discharge\"] * 86400, x[\"area_km2\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df[\"gauge_id\"] = df[\"code\"].astype(str)\n",
    "\n",
    "    return df[[\"date\", \"gauge_id\", \"discharge\", \"discharge_spec\"]]\n",
    "\n",
    "\n",
    "# Process each country\n",
    "kgz_processed = process_discharge_data(kgz_streamflow, kgz_basins)\n",
    "tjik_processed = process_discharge_data(tjik_streamflow, tjik_basins)\n",
    "\n",
    "# Merge the two dataframes\n",
    "merged_processed = pd.concat([kgz_processed, tjik_processed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter dates from 2000 onwards\n",
    "merged_processed_filtered = merged_processed[merged_processed[\"date\"] >= \"2000-01-01\"]\n",
    "\n",
    "\n",
    "# 2. Handle duplicates\n",
    "def get_first_valid(group):\n",
    "    # Sort by discharge_spec to get NaN values last\n",
    "    group = group.sort_values(\"discharge_spec\", na_position=\"last\")\n",
    "    # Return the first row (which will be non-NaN if any exist)\n",
    "    return group.iloc[0]\n",
    "\n",
    "\n",
    "# Group by date and gauge_id, apply the function\n",
    "merged_processed_cleaned = merged_processed_filtered.groupby(\n",
    "    [\"date\", \"gauge_id\"], as_index=False\n",
    ").apply(get_first_valid)\n",
    "\n",
    "# 3. Pivot the table\n",
    "merged_processed_pivoted = merged_processed_cleaned.pivot(\n",
    "    index=\"date\", columns=\"gauge_id\", values=\"discharge_spec\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To CSV\n",
    "merged_processed_pivoted.to_csv(\n",
    "    \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/CA_streamflow_for_caravan.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(df):\n",
    "    \"\"\"\n",
    "    Check for duplicates in a dataframe based on date and gauge_id combinations.\n",
    "    Returns information about duplicate entries.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with 'date' and 'gauge_id' columns\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (duplicate_counts, duplicate_examples)\n",
    "    \"\"\"\n",
    "    # Check for duplicates based on date and gauge_id combination\n",
    "    duplicates = df.groupby(['date', 'gauge_id']).size().reset_index(name='count')\n",
    "    duplicate_rows = duplicates[duplicates['count'] > 1]\n",
    "    \n",
    "    # Get example records for each duplicate combination\n",
    "    if not duplicate_rows.empty:\n",
    "        example_duplicates = pd.DataFrame()\n",
    "        for _, row in duplicate_rows.iterrows():\n",
    "            mask = (df['date'] == row['date']) & (df['gauge_id'] == row['gauge_id'])\n",
    "            example_duplicates = pd.concat([example_duplicates, df[mask]])\n",
    "    else:\n",
    "        example_duplicates = pd.DataFrame()\n",
    "    \n",
    "    return duplicate_rows, example_duplicates\n",
    "\n",
    "# Get duplicate information\n",
    "duplicate_counts, duplicate_examples = check_duplicates(merged_processed)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nDuplicate combinations found:\")\n",
    "print(duplicate_counts)\n",
    "\n",
    "print(\"\\nExample duplicate records:\")\n",
    "print(duplicate_examples.sort_values(['date', 'gauge_id']))\n",
    "\n",
    "# Get total number of duplicate combinations\n",
    "total_duplicates = len(duplicate_counts)\n",
    "print(f\"\\nTotal number of date-gauge_id combinations with duplicates: {total_duplicates}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare basins shapefiles for Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_kgz_basins = \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/basin_outline/kyrgyzstan/HRU_KRG_ML_MODEL_BASINS_1d.shp\"\n",
    "path_to_tjik_basins = \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/basin_outline/tajikistan/HRU_TAJIK_ML_MODEL_BASINS_1d.shp\"\n",
    "\n",
    "kgz_basins = gpd.read_file(path_to_kgz_basins)\n",
    "tjik_basins = gpd.read_file(path_to_tjik_basins)\n",
    "\n",
    "rename_mapping = {\n",
    "    \"CODE\": \"gauge_id\",\n",
    "}\n",
    "\n",
    "kgz_basins = kgz_basins.rename(columns=rename_mapping)\n",
    "tjik_basins = tjik_basins.rename(columns=rename_mapping)\n",
    "\n",
    "columns_to_keep = [\"gauge_id\", \"geometry\"]\n",
    "\n",
    "kgz_basins = kgz_basins[columns_to_keep]\n",
    "tjik_basins = tjik_basins[columns_to_keep]\n",
    "\n",
    "# Merge the two geo dataframes\n",
    "merged_basins = pd.concat([kgz_basins, tjik_basins])\n",
    "\n",
    "# Save as shapefile\n",
    "output_path = \"/Users/cooper/Desktop/CAMELS-CH/data/CA_raw/CA_basins_for_gee.shp\"\n",
    "\n",
    "# Print crs\n",
    "print(merged_basins.crs)\n",
    "\n",
    "merged_basins.to_file(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the basins\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "merged_basins.plot(ax=ax, color=\"blue\", edgecolor=\"black\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
